<!doctype html>
  <script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<html style="font-size: 16px;" lang="en"><head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="keywords" content="Post 1 Headline">
    <meta name="description" content="">
    <title>Optimization series part 1: general idea</title>
    <link rel="stylesheet" href="../nicepage.css" media="screen">
<link rel="stylesheet" href="../Post-Template.css" media="screen">
    <script class="u-script" type="text/javascript" src="../jquery.js" defer=""></script>
    <script class="u-script" type="text/javascript" src="../nicepage.js" defer=""></script>
    <meta name="generator" content="Nicepage 4.14.1, nicepage.com">
    <link id="u-theme-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i|Open+Sans:300,300i,400,400i,500,500i,600,600i,700,700i,800,800i">
    
    
    <script type="application/ld+json">{
		"@context": "http://schema.org",
		"@type": "Organization",
		"name": "",
		"logo": "images/owanlogo.png",
		"sameAs": [
				"https://www.facebook.com/owan.naruemit",
				"https://twitter.com/napanaruemit",
				"https://www.linkedin.com/in/pethai-napanaruemit-3a69a7190/",
				"https://github.com/pethai2004",
				"https://www.youtube.com/channel/UCkQZQFB-PPBgNEL-GizSucw"
		]
}</script>
    <meta name="theme-color" content="#478ac9">
    <meta name="twitter:site" content="@">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Post Template">
    <meta name="twitter:description" content="">
  </head>
  <body class="u-body u-xl-mode" data-lang="en"><header class="u-clearfix u-header u-palette-1-light-2 u-header" id="sec-b8de"><div class="u-clearfix u-sheet u-sheet-1">
        <a href="../Home.html" data-page-id="208602995" class="u-image u-logo u-image-1" data-image-width="1000" data-image-height="1000" title="Home">
          <img src="../images/owanlogo.png" class="u-logo-image u-logo-image-1">
        </a>
        <nav class="u-menu u-menu-dropdown u-offcanvas u-menu-1">
          <div class="menu-collapse" style="font-size: 1rem; letter-spacing: 0px; font-weight: 700;">
            <a class="u-button-style u-custom-left-right-menu-spacing u-custom-padding-bottom u-custom-top-bottom-menu-spacing u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="#">
              <svg class="u-svg-link" viewBox="0 0 24 24"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#menu-hamburger"></use></svg>
              <svg class="u-svg-content" version="1.1" id="menu-hamburger" viewBox="0 0 16 16" x="0px" y="0px" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><g><rect y="1" width="16" height="2"></rect><rect y="7" width="16" height="2"></rect><rect y="13" width="16" height="2"></rect>
</g></svg>
            </a>
          </div>
          <div class="u-custom-menu u-nav-container">
            <ul class="u-nav u-unstyled u-nav-1"><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="../Home.html" style="padding: 10px 20px;">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="../project-and-code.html" style="padding: 10px 20px;">project and code</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="../lecture.html" style="padding: 10px 20px;">lecture</a>
</li></ul>
          </div>
          <div class="u-custom-menu u-nav-container-collapse">
            <div class="u-black u-container-style u-inner-container-layout u-opacity u-opacity-95 u-sidenav">
              <div class="u-inner-container-layout u-sidenav-overflow">
                <div class="u-menu-close"></div>
                <ul class="u-align-center u-nav u-popupmenu-items u-unstyled u-nav-2"><li class="u-nav-item"><a class="u-button-style u-nav-link" href="../Home.html">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="../project-and-code.html">project and code</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="../lecture.html">lecture</a>
</li></ul>
              </div>
            </div>
            <div class="u-black u-menu-overlay u-opacity u-opacity-70"></div>
          </div>
        </nav>
      </div></header>
    <section class="u-align-center u-clearfix u-section-1" id="sec-bf54">
      <div class="u-clearfix u-sheet u-valign-middle-md u-valign-middle-sm u-valign-middle-xs u-sheet-1"><!--post_details--><!--post_details_options_json--><!--{"source":""}--><!--/post_details_options_json--><!--blog_post-->
        <div class="u-container-style u-expanded-width u-post-details u-post-details-1">
          <div class="u-container-layout u-valign-middle u-container-layout-1", style= "position: center;padding: 0px 100px 5px 100px;"><!--blog_post_image-->
            <!--/blog_post_image--><!--blog_post_header-->
            <h2 class="u-blog-control u-text u-text-1">Optimization series part 1: general idea</h2><!--/blog_post_header--><!--blog_post_metadata-->
            <div class="u-blog-control u-metadata u-metadata-1"><!--blog_post_metadata_date-->
              <span class="u-meta-date u-meta-icon">May 19, 2022</span><!--/blog_post_metadata_date--><!--blog_post_metadata_category-->
              <!--/blog_post_metadata_category--><!--blog_post_metadata_comments-->
              <!--/blog_post_metadata_comments-->
            </div><!--/blog_post_metadata--><!--blog_post_content-->
            <div style= "position: center;">

<h4>Optimality Condition</h4>
<p>
First intuitive thing when saying \( f\) is the local minimum, the gradient \( g=\nabla f=0\), since there's no direction gradient could point to, we could decrease the function by following negative gradient. And its hessian at local minimum \( H=\nabla ^{2} f\geqslant 0\) is positive semi-definite (\( S_{+}\)). Note however that the converse is not true, the gradient \( g=0\) does not implied local minimum. For example, if \( f=x^{3}\) and \( \nabla f=3x^{2} =0,\ x=0\) but is not either local minimum or maximum, it is saddle point. Since second derivative tells us about concavity, thinking only single variable, positive \( d^{2} f\) is when \( f\) is concave upward, and negative when downwards. So does the hessian \( H\), it is positive semi-definite when \( f\) is concave upward, \( f( x_{0}) < f( x)\) around its neighborhood. Note also that the converse is not true. This is called neccessary condition, the condition that go one direction,\( \Rightarrow \)but not\( \Leftarrow \)(sufficient condition).
<p>
\(Theorem\) 1 (Necessary condition) if  \( x^{*}\) is local minimizer and \( f\) is twice differentiable, then \( \nabla f\left( x^{*}\right) =0\) and \( \nabla ^{2} f\left( x^{*}\right) =0\) is positive semi-definite.
</p>
<p>
\(Theorem\) 2 (Sufficient condition) if \( g=\nabla f\left( x^{*}\right) =0\) and \( \nabla ^{2} f\left( x^{*}\right)\) is positive definite, then \( x^{*}\) is a strict local minimizer of \( f\).
</p>
Note that when \( f( x_{0})\) is saddle point, the eigenvalue will be the mixed of positive and negative but gradient will be zeros, so it is no sufficient of zeros gradient. Note also what it mean to say we can still following the negative gradient direction: let \( p=-\nabla f\), the direction of negative gradient so \( p^{T} \nabla f=-\| \nabla f\| ^{2}\). Suppose \( f\) is continuous, for some small \( t\), \( p^{T} \nabla f\left( x^{*} +tp\right) < 0\). Forming taylor expansion, \( f\left( x^{*} +tp\right) =f\left( x^{*}\right) +p^{T} t\nabla f\left( x^{*} +tp\right) < f\left( x^{*}\right)\), there exist direction \( p\) in which it minimize \( f\). This is applicable when we assume the gradient is not zero. It can be done also for hessian by assuming \( H\) is not positive semi-definite and forming second-order taylor expandsion. This borrow from book numerical optimization. 
</p>
<p>
Convex function ## see more about convex optimization on lecture ***
\( f\) is convex if and only if \( \nabla ^{2} f\geqslant 0,\ \forall x\in domf\).
\( f\) is strict convex if  \( \nabla ^{2} f >0\), \( \forall x\in domf\), the converse is not true.
\( f\) is strong convex if and only if \( \nabla ^{2} f\geqslant m\geqslant 0\), \( \forall x\in domf\).

Recall (for ref.): Taylor expansion
\begin{gather}
f( x+p) =f( x) +\nabla f( x+tp)^{T} p,\\
\nabla f( x+p) =\nabla f( x) +\int _{0}^{1} \nabla ^{2} f( x+tp) p\ dt\\
f( x+p) =f( x) +\nabla f( x)^{T} p+\frac{1}{2} p^{T} \nabla ^{2} f( x+tp) p
\end{gather}
and \( \ t\ \in ( 0,1) ,\ f:\ \mathbb{R} ^{n}\rightarrow \mathbb{R} \ \)is twice differentiable.

Note that to be convex, the hessian \( H\) must be positive semi-definite, it is a bowl and is concave upward. For one variables, \( f^{''}( x) \geqslant 0,\forall x\in domf\), \( f\) has nonnegative curvature. Since, from necessary condition, the local minimum of convex function is its global since the hessian of convex function is positive semi-definite. 
The degree of smoothness can be quantified by Lipschitz continuous which say if we change \( x\) by unit, the different to objective cannot more some value of \( K\), \( |f( x_{0}) -f( x_{1}) |\leqslant L|x_{0} -x_{1} |\), in other word, it limit how fast \( f\) can change. For non-smooth problem such as regularized objective in machine learning, we seperate \( f=f_{smooth} +f_{nonsmooth}\) where the second term is, for example L2 norm of the parameters. 
</p>

<p>
Descent direction: \( p\) #\( p\) is descent if angle between \( p\) and gradient is less that \( \pi /2\) and \( p^{T} g< 0\).
Consider the objective \( f( \theta )\), \( p\) is descent direction if it exist \( f( \theta +\alpha p) < f( \theta )\), we found small objective after following that direction. The question is what is an appropriate constant \( \alpha \) (step-size) and direction \( p\) that result in reduction in objective function \( f\). So we have update rule starting from some initial guess, \( x_{k}\), \( x_{k+1} =x_{k} +\alpha _{k} p_{k}\), I will later use \( x\) in place of \( \theta \) interchangeably. Recall: The gradient vector \( \nabla f\cdot d\vec{r} /dt=0\), the gradient vector is orthogonal to tangent line where the tangent is pointing in the same direction as level curve. The directional derivative, \( D_{p} =p^{T} \nabla f=||\nabla f||\ ||p||\cos \theta \) (from definition). The point here is to varying \( \theta \) such that it result in decrease/increase in \( f\). If \( \theta =\pi /2\), \( \cos \theta =0\) and we travel along level curve \( d\vec{r} /dt\), then there is no change in \( f\). This is not of interest. When \( \theta =0\) and \( \theta =\pi \), the direction \( p\) is parallel to gradient \( \nabla f\) and so a steepest direction. We can go any direction by varyiny \( \theta \) and still in descent direction if \( 0\leqslant \theta \leqslant \pi /2\). Thus \( ||\nabla f||\ ||p||\cos \theta < 0\). The same go for ascent direction but change the sign. Another way to think about this is we like to find the maximum slope, 
\begin{equation}
\mathbf{max}_{p} D_{p} =\mathbf{max}_{p} p^{T} \nabla f
\end{equation}
The solution is \( p=\nabla f/||\nabla f||\) when \( \cos \theta =1\). The same go for descent direction, change max to min. Actually I could just mension only the degree of \( \theta \) in descent direction, why bother with ascent on since it's identical.
</p>
<h4>Line Search Method </h4> \( \alpha _{k} =\mathbf{argmin}_{\alpha  >0} f( x_{k} +\alpha p_{k}) =\mathbf{argmin}_{\alpha  >0} \Psi _{k}( \alpha )\).
<p>Assume already determined the direction \( p_{k}\), the goal is to find \( \alpha \) that best minimize \( \Psi _{k}( \alpha )\). Exhaustive evaluation is an ideal but is not tractable in general, this is called exact line search. Inexact line search on the other hand choose \( \alpha \) that also minimize \( \Psi \) (hense the reduction in original \( f\)) and is satisfied some condition. 

Wolfe Condition: (sufficient decrease) require \( \alpha _{k}\) to satisfy the reduction test in \( f\): \( f( x_{k} +\alpha p_{k}) \leqslant f( x_{k}) +l( \alpha )\), and \( l( \alpha ) =c_{1} \alpha \nabla f_{k}^{T} p_{k}\)(Armijo condition). The condition say that \( \Phi ( \alpha ) =f( x_{k} +\alpha p_{k})\) must be \( \Phi ( \alpha ) \leqslant l( \alpha )\) so that the step size \( \alpha \) is acceptable. Note that \( l( \alpha )\) is linear and line above \( \Phi \). But the function \( \Phi ( \alpha )\) can contain many values, to ensure that the algorithm make the progression or the best step size, we require curvature condition. (Curvature Condition) require \( \alpha _{k}\) to satisfy \( \nabla f(x_{k} +a_{k} p_{k} )^{T} p_{k} \geq c_{2} \nabla f(x_{k} )^{T} p_{k}\) where \( c_{2} \in [ c_{1} ,1]\), typically 0.9. It tells us that the step shoud be large enough. 

- Gradient descent (Other variants of gradient descent can be found in my machine learning lecture series.)
Convergence (theorem 3.2 of numerical optimization)
With gradient bounded Lipshitz continuous, GD converges at a linear rate with \( \mu \) (rate of converge)\( |f( x_{k+1}) -f\left( x^{*}\right) |\leqslant \mu |f( x_{k}) -f\left( x^{*}\right) |\). And \( \sum _{k}\cos^{2} x_{k} ||\nabla f_{k} ||^{2} < \infty \), where \( \cos x_{k} =\frac{-\nabla f_{k}^{T} p_{k}}{\| \nabla f_{k} \| \ \| p_{k} \| }\)
The Zoutendijk condition implies that \( \cos^{2} x_{k} ||\nabla f_{k} ||^{2} < \infty \), this limit can be used to derive global convergence results for line search algorithm (for example, where \( f\) is a quadratic form). (p.280 Murphy) We can be sure that \( \| \nabla f_{k} \| \rightarrow 0\) (approach critical point) provided that search direction \( p\) are never (always) close to orthogonality with gradient (parallel with \( \nabla f\)). If the chosen line search ensure that \( \theta _{k} < \pi /2\) then \( \cos \theta _{k} \geqslant \delta  >0\) for all \( k\) and that \( \lim _{k\rightarrow \infty } \| \nabla f_{k} \| =0\). In steepest descent, as mentioned, \( p\) is parallel to negative gradient \( -\nabla f\) and that \( \lim _{k\rightarrow \infty } \| \nabla f_{k} \| =0\), sequence of gradient converge to zeros provided that it use a line search satisfied Wolfe or Goldstein condition. This view is the key property to designing algorithm such that the search direction is not tend to orthogonal to gradient \( \nabla f\) since, intuitively, can be think like circle around the mountain but never go up and down. We could compute cos\theta_k at every iteration and turn \( p\) toward steepest direction if  \( \cos \theta _{k} \geqslant \delta  >0\). But this are undesirable, inappropriate \( \delta \)may slow down convergence rate (ill-conditioned Hessian, rapid change in gradient) that may necessary to produce \( p\) almost orthogonal to gradient.</p>

<h4>Stochastic gradient descent</h4>
<p>
Optimize over expectation of objective, \( \mathbb{E}_{p( x)}[ L( \theta ,x)]\) where \( x\) is input to objective for example neural network parametrized by \( \theta \). It is stochatics since \( x\) is sampled from \( p\) and assuming \( \theta \) is independent from distribution \( p\). In emprical risk mininization, the gradient can be, instead of full gradient of \( N\) term, approximate by minibatch of size \( D\), \( g=\frac{1}{|D|}\sum _{n=1}^{D} \nabla _{\theta } L\). 
(control variate) SGD. note that this technique is difficult in many application is DL. 
1. SVRG : \( g_{k} =\nabla L_{t}( \theta ) -\nabla L_{t}\left(\tilde{\theta }\right) +\nabla L\left(\tilde{\theta }\right)\)The gradient \( g_{t}\) is unbiased, \( \mathbb{E} _{t}\left[ \nabla L_{t}\left(\tilde{\theta }\right)\right] =\nabla L\left(\tilde{\theta }\right)\), the term vanished. The baseline gradient \( \nabla L_{t}\left(\tilde{\theta }\right)\) is fixed. The inner loop use effort same as SGD, it only need to compute \( \nabla L_{t}( \theta )\) and \( \nabla L_{t}\left(\tilde{\theta }\right)\). The outer loop require full batch gradient which will be used to compare to stochastic in the inner loop, \( \nabla L_{t}( \theta )\). 2. SAGA  see more #TODO <;p>

<h4>(preconditioning) SGD </h4>,<p> \( x_{k+1}\leftarrow x_{k} +\alpha _{k} M_{t}^{-1} \nabla f( x_{k})\)
Let matrix \( M_{k}\) is symetric positive-definite and \( M_{k} =A_{k}^{T} A_{k}\). Let \( \hat{x} =A_{k}^{T} x\), a linear transformation of \( x\) so \( x=A_{k}^{-T}\hat{x}\). We optimized over transformed \( \hat{x}\), \( \hat{x}_{k+1}\leftarrow \hat{x}_{k} +\alpha \nabla f(\hat{x})\). Calculating the derivative : 
\begin{gather}
\hat{x}_{k+1}\leftarrow \hat{x}_{k} +\alpha \nabla f\left( A_{k}^{-T}\hat{x}_{k}\right)\\
\hat{x}_{k+1}\leftarrow \hat{x}_{k} +\alpha A_{k}^{-1} \nabla f\left( A_{k}^{-T}\hat{x}_{k}\right)\\
A_{k}^{-T} x_{k+1} =A_{k}^{-T}\hat{x}_{k} +\alpha A_{k}^{-1} \nabla f(\hat{x}_{k})\\
A_{k}^{-T} A_{k}^{-T} x_{k+1} =A_{k}^{-T} A_{k}^{-T}\hat{x}_{k} +\alpha A_{k}^{-T} A_{k}^{-1} \nabla f( x_{k})\\
x_{k+1}\leftarrow x_{k} +\alpha M_{k}^{-1} \nabla f( x_{k}) \notag
\end{gather}
where \( M\) is preconditioned matrix. In practice it is diagonal matrix, it require less computation. This can be hessian but in SGD, to gradient estimate is often noise aand hard to use method that approximate hessian based on gradient such as GFGS. For example the update it AdaGrad can be viewed as preconditioned gradients: \) \)\( M_{T} =diag( s_{t} +eps)^{1/2}\) where square root is element-wise and \( s\) is summed of squared gradient, the update is \( \theta _{k+1}\leftarrow \theta _{k} -\alpha _{k} /g\sqrt{s+eps}\). Full preconditioned matrix \( M\), for adagrad, Full-matrix Adagrad is also possible. (see more Murphy p.295) In addition, to determine that the direction, \( p_{k} =-M_{k}^{-1} \nabla f( x_{k})\) is in descent direction, \( \nabla f( x_{k})^{T} p_{k} =-\nabla f( x_{k}) M_{k}^{-1} \nabla f( x_{k}) < 0\) is descent direction (\( M\) is \( S_{++}\)).
 </p>

<h4>Second order method</h4>
<p>
1. Newton Method: Let first forming second-order taylor approximation to \( f\) that we want to optimize over:
\begin{equation}
f( x+p) =m_{k}( x) \approx f+\nabla f^{T}( x) p+\frac{1}{2} p^{T} \nabla ^{2} f( x+tp) p
\end{equation}
Taking its derivative and set to zeros yield \( \nabla m_{k}( x) =0,\nabla f+\nabla ^{2} fp\), so the search direction is \( p=-\nabla f/\nabla ^{2} f\). The update rules is then \( x_{k+1}\leftarrow x_{k} +\alpha p_{k} =x_{k} -\alpha H^{-1} g\). This assuming that the hessian is postive-definite, but this isn't always the case. So we could integrate this direction to gradient descent if the approximation if well good, since the update rules is derived from quadratic approximation \( m_{k}( x)\) not the true function \( f_{k}( x)\). We could also incorporate linesearch too. The procedure of computing is first evaluete gradient and hessian (exact hessian) and solving the linear system, \( H_{k} p=-g_{k}\) for \( d\) using either elimination or conjugate gradient method etc.. and perform line search \( \alpha \) in the direction of \( p=-g/H^{-1}\). Note that most implementation use \( \alpha =1\) and decrese if function not decrease. And if hessian isn't positive definite, the inverse do not exist. Recall: Semidefinite matrix has at least one 0 eigenvalue so it vanishes the determinant. This is singular and not invertible. As a result, cannot apply the direction. This is solved by modifying hessian while preserve the information in hessian. We can see that the gradient descent is special case of modified newton method where the hessian is replaced by identity, meaning that no second-order information such as curvature or skewness that gained from hessian. 

2. Quasi-Newton Method
This is newton's method with approximated hessian. We write, from Taylor’ theorem, 
\begin{equation*}
\nabla f( x+p) =\nabla f( x) +\int _{0}^{1} \nabla ^{2} f( x+tp) p\ dt
\end{equation*}
, and setting \( x=x_{k}\) and \( p=x_{k+1} -x_{k}\), we have ( size of final integral is \( O( \| p\| )\) .) \( \nabla f_{k+1} =\nabla f_{k} +\nabla ^{2} f_{k}( x_{k+1} -x_{k}) +O( \| x_{k+1} -x_{k} \| )\).  We approximate a new Hessian \( B\) that mimics the property \( \nabla ^{2} f_{k}( x_{k+1} -x_{k}) \approx \nabla f_{k+1} -\nabla f_{k}\) and satisfied secant equation: \( B_{k+1} s_{k} =y_{k}\), where \( s_{k} =x_{k+1} -x_{k}\) and \( y_{k} =\nabla f_{k+1} -\nabla f\). We typically set condition on \( B\), for example, symmetry (exact Hessian is symmetry) and two successive \( B_{k+1}\) and \( B_{k}\) has low rank. Two popular formulae for updating Hessian are symmetric-rank-one and BFGS. We then can replace approximate in newton direction as \)p_{k} =-B_{k}^{-1} \nabla f_{k}\). In practice we can update inverse of Hessian instead of the need to factorize/back-substitution of stated updating formula, we applied  \( H=-B_{k}^{-1}\) and use \( p_{k} =H_{k} \nabla f_{k}\). In summary, often search direction has the form of \( p_{k} =-B_{k}^{-1} \nabla f_{k}\)  where \( B\) is identity for steepest descent, and exact Hessian for Newton’s method and approximate Hessian for quasi-Newton.
</p>

<h>Trust Region Method </h> \( p_{k} =\mathbf{argmin}_{p\in \epsilon } f( x_{k} +\alpha _{k} p) =\mathbf{argmin}_{p\in \epsilon } \Phi _{k}( p)\). #TODO 1 2 3
The key is to formulize the second optimization problem at each time steps and perform optimizing on that one instead. We choose maximum search distance of ball-\( r\), the set \( B_{r} =\{x\in M|d( x,c) < r\}\) where \( c\) is the center. We gather local information in neighborhood of \( f\) by its approximation \( m\) which is its local approximation. Trust region solve this subproblem by finding direction \( p_{k}\), minimizing local \( m\) is equivalent to minimizing \( f\):  
\begin{equation}
\mathbf{min}_{p} m_{k}( x_{k} +p) ,\ \mathbf{subject} \ to\ x_{k} +p\leqslant r
\end{equation}
Usually \( m\) is defined to be quadratic: \( m_{k}( x_{k} +p) =f_{k} +p^{T} \nabla f_{k} +1/2p^{T} H_{k} p\), here \( H\) could be exact or approximation of hessian. Or \( m\) cound be linear model (exclude last term of quadratic). The key is chossing appropriate step size, the radius of region \( r\) and perform search direction \( p\). 

<h4>Conjugate Gradient Method </h4>#TODO 1 
<p>
Originaly design for solving linear system of \( Ax=b\), is equivalent to miniming convex quadratic function of the form \( \phi ( x) =1/2\ x^{T} Ax-b^{T} x+b\), assuming \( A\) is \( S_{++}\). This method has the form \( p_{k} =-\nabla f( x_{k}) +\beta _{k} p_{k-1}\) where \( \beta _{k}\) ensure that the two successive \( p_{k}\) and \( p_{k+1}\) is conjugate. Its performance is determined by the distribution of eigenvalues of matrix \( A\), it can also be preconditioned to make it more efficient on improving convergence. Note that we differentiate \( f\) and set to zero to obtain similar linear system. The gradient \( \nabla \phi ( x)\) is the residual of the linear system: \( \nabla \phi ( x) =b-Ax=r\), satisfies \( r=0\). We can measure how much the solution yeild from CG failed to deviate from true solution by relative residual: \( \delta =\| r\| /\| b\| \). Note that CG generate sets of vectors with a conjugcy property: A set of nonzeros vectors \( \{v_{i}\}\) is said to be conjugate with respect to positive definite matrix \( A\) if \( p_{i}^{T} Ap_{j} =0\) for all \( i\neq j\). It can be showed that it is also linearly independent. We update \( x_{k+1}\leftarrow x_{k} +a_{k} p_{k}\), where \( a_{k}\) is one-dimensional minimizer off quadratic function\( \phi \) along \( x_{k} +a_{k} p_{k}\), given by \)a_{k} =-\frac{r_{k}^{T} p_{k}}{p_{k}^{T} Ap_{k}}\). This can be shown by simply differentiating and set it to zero then solve for \( a_{k}\):   (exercise 3.3). We arrive at following theorem: 
<p>
<img src="image/opt001.png" alt="theorem01", style="width:100;height:50px;">
</p>
Note that CG is less memory consumption since its require only previous \( p_{k-1}\) in generating conjugate set \( p_{k}\). Note in numerical optimization definded residual as \( r=Ax-b\). So the search direction is linear combination of negative residual \( -r_{k}\) and \( p_{k-1}\): \( p_{k} =-r_{k} +\beta _{k} p_{k-1}\). And (5.14d) can be obtained by multiplying \( p_{k} =-r_{k} +\beta _{k} p_{k-1}\) by \( p_{k-1}^{T} A\) and use conjugacy property: \( p_{k-1}^{T} Ap_{k} =0\). The first search direction \( p_{0}\) is chosen to be descent direction. Theorem 5.3 (5.16) suggest that residuals \( r_{k}\) are mutually orthogonal. Each search direction and residual is contained in Krylov subspace of degree \( k\) for \( r_{0}\) defined as \( \mathfrak{R} ( r_{0} ;k) \equiv \mathbf{span}\left\{r_{0} ,Ar_{0} ,...,A^{k} r_{0}\right\}\). More practical version of CG is replacing (5.14a) by \( a_{k} =-\frac{r_{k}^{T} r_{k}}{p_{k}^{T} Ap_{k}}\) and (5.14b) by \( \beta _{k} =\frac{r_{k+1}^{T} r_{k+1}}{r_{k}^{T} r_{k}}\)(see p.111).
</p>

<h4>Precondtioned CG</h4>
<p>
Key idea is to transform \( x\) to \)\hat{x} =Cx\), where C is nonsingular (i.e., Zero det and invertible). And transform quadratic \( \phi \) by \)\hat{\phi }(\hat{x}) =\frac{1}{2} x^{T} (C^{-T} AC^{-1} )\hat{x} -\left( C^{-T} b\right)^{T}\hat{x}\) and is equivalent to solve the linear system \)(C^{-T} AC^{-1} )\hat{x} =C^{-T} b\). The convergence rate depend on eigenvalues of \)C^{-T} AC^{-1}\) and we choose \)C\) such that the eigenvalues are more favorable (see p. 112 for theoretical analysis of convergence rate). We can choose \)C\) such that condition number is smaller than original one or such that the eigenvalues of transformed matrix are clustered. It unnecessary to use direct transformation, rather, we apply \)\hat{x}\) in algorithm then revert equation in terms of original \( x\).

The matrix M do not use \)C\), but rather \( M=C^{T} C\), which is symmetric and positive definite by construction. If \( M=\mathbb{I} \), it reduces to standard CG. The orthogonal property of \( r_{j} r_{i} =0\) becomes \( r_{j} M^{-1} r_{i} =0\), for all \( i\neq j\). Some general precondition strategies include (SSOR), incomplete Cholesky, and banded preconditioners. In general, there is no exact strategy that is best, it’s depend on problem. Nonlinear CG method This apply to problem of minimizing general convex functions or nonlinear functions. This is well studied method and proved to be quite successful. Some method include: Fletcher-Reeves Method Polak-Ribiere method and its variants Quadratic termination and Restarts
</p>
<p>
  <img src="image/opt002.png" alt="op01", style="width:300;height:180px;">
<img src="image/opt003.png" alt="op02", style="width:300;height:180px;">
<img src="image/opt004.png" alt="op03", style="width:300;height:180px;">
  </p>
</div>
</div>
          </div>
        </div><!--/blog_post--><!--/post_details-->
      </div>
    </section>
    
    
    <footer class="u-clearfix u-footer u-grey-80" id="sec-e381"><div class="u-clearfix u-sheet u-sheet-1">
        <div class="u-align-left u-social-icons u-spacing-10 u-social-icons-1">
          <a class="u-social-url" title="facebook" target="_blank" href="https://www.facebook.com/owan.naruemit"><span class="u-icon u-social-facebook u-social-icon u-icon-1"><svg class="u-svg-link" preserveAspectRatio="xMidYMin slice" viewBox="0 0 112 112" style=""><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#svg-9909"></use></svg><svg class="u-svg-content" viewBox="0 0 112 112" x="0" y="0" id="svg-9909"><circle fill="currentColor" cx="56.1" cy="56.1" r="55"></circle><path fill="#FFFFFF" d="M73.5,31.6h-9.1c-1.4,0-3.6,0.8-3.6,3.9v8.5h12.6L72,58.3H60.8v40.8H43.9V58.3h-8V43.9h8v-9.2
            c0-6.7,3.1-17,17-17h12.5v13.9H73.5z"></path></svg></span>
          </a>
          <a class="u-social-url" title="twitter" target="_blank" href="https://twitter.com/napanaruemit"><span class="u-icon u-social-icon u-social-twitter u-icon-2"><svg class="u-svg-link" preserveAspectRatio="xMidYMin slice" viewBox="0 0 112 112" style=""><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#svg-d07a"></use></svg><svg class="u-svg-content" viewBox="0 0 112 112" x="0" y="0" id="svg-d07a"><circle fill="currentColor" class="st0" cx="56.1" cy="56.1" r="55"></circle><path fill="#FFFFFF" d="M83.8,47.3c0,0.6,0,1.2,0,1.7c0,17.7-13.5,38.2-38.2,38.2C38,87.2,31,85,25,81.2c1,0.1,2.1,0.2,3.2,0.2
            c6.3,0,12.1-2.1,16.7-5.7c-5.9-0.1-10.8-4-12.5-9.3c0.8,0.2,1.7,0.2,2.5,0.2c1.2,0,2.4-0.2,3.5-0.5c-6.1-1.2-10.8-6.7-10.8-13.1
            c0-0.1,0-0.1,0-0.2c1.8,1,3.9,1.6,6.1,1.7c-3.6-2.4-6-6.5-6-11.2c0-2.5,0.7-4.8,1.8-6.7c6.6,8.1,16.5,13.5,27.6,14
            c-0.2-1-0.3-2-0.3-3.1c0-7.4,6-13.4,13.4-13.4c3.9,0,7.3,1.6,9.8,4.2c3.1-0.6,5.9-1.7,8.5-3.3c-1,3.1-3.1,5.8-5.9,7.4
            c2.7-0.3,5.3-1,7.7-2.1C88.7,43,86.4,45.4,83.8,47.3z"></path></svg></span>
          </a>
          <a class="u-social-url" title="linkedin" target="_blank" href="https://www.linkedin.com/in/pethai-napanaruemit-3a69a7190/"><span class="u-icon u-social-icon u-social-linkedin u-icon-3"><svg class="u-svg-link" preserveAspectRatio="xMidYMin slice" viewBox="0 0 112 112" style=""><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#svg-694a"></use></svg><svg class="u-svg-content" viewBox="0 0 112 112" x="0" y="0" id="svg-694a"><circle fill="currentColor" cx="56.1" cy="56.1" r="55"></circle><path fill="#FFFFFF" d="M41.3,83.7H27.9V43.4h13.4V83.7z M34.6,37.9L34.6,37.9c-4.6,0-7.5-3.1-7.5-7c0-4,3-7,7.6-7s7.4,3,7.5,7
            C42.2,34.8,39.2,37.9,34.6,37.9z M89.6,83.7H76.2V62.2c0-5.4-1.9-9.1-6.8-9.1c-3.7,0-5.9,2.5-6.9,4.9c-0.4,0.9-0.4,2.1-0.4,3.3v22.5
            H48.7c0,0,0.2-36.5,0-40.3h13.4v5.7c1.8-2.7,5-6.7,12.1-6.7c8.8,0,15.4,5.8,15.4,18.1V83.7z"></path></svg></span>
          </a>
          <a class="u-social-url" target="_blank" data-type="Github" title="Github" href="https://github.com/pethai2004"><span class="u-icon u-social-github u-social-icon u-icon-4"><svg class="u-svg-link" preserveAspectRatio="xMidYMin slice" viewBox="0 0 112 112" style=""><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#svg-a39c"></use></svg><svg class="u-svg-content" viewBox="0 0 112 112" x="0" y="0" id="svg-a39c"><circle fill="currentColor" cx="56.1" cy="56.1" r="55"></circle><path fill="#FFFFFF" d="M88,51.3c0-5.5-1.9-10.2-5.3-13.7c0.6-1.3,2.3-6.5-0.5-13.5c0,0-4.2-1.4-14,5.3c-4.1-1.1-8.4-1.7-12.7-1.8
	c-4.3,0-8.7,0.6-12.7,1.8c-9.7-6.6-14-5.3-14-5.3c-2.8,7-1,12.2-0.5,13.5C25,41.2,23,45.7,23,51.3c0,19.6,11.9,23.9,23.3,25.2
	c-1.5,1.3-2.8,3.5-3.2,6.8c-3,1.3-10.2,3.6-14.9-4.3c0,0-2.7-4.9-7.8-5.3c0,0-5-0.1-0.4,3.1c0,0,3.3,1.6,5.6,7.5c0,0,3,9.1,17.2,6
	c0,4.3,0.1,8.3,0.1,9.5h25.2c0-1.7,0.1-7.2,0.1-14c0-4.7-1.7-7.9-3.4-9.4C76,75.2,88,70.9,88,51.3z"></path></svg></span>
          </a>
          <a class="u-social-url" target="_blank" data-type="YouTube" title="YouTube" href="https://www.youtube.com/channel/UCkQZQFB-PPBgNEL-GizSucw"><span class="u-icon u-social-icon u-social-youtube u-icon-5"><svg class="u-svg-link" preserveAspectRatio="xMidYMin slice" viewBox="0 0 112 112" style=""><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#svg-7985"></use></svg><svg class="u-svg-content" viewBox="0 0 112 112" x="0" y="0" id="svg-7985"><circle fill="currentColor" cx="56.1" cy="56.1" r="55"></circle><path fill="#FFFFFF" d="M74.9,33.3H37.3c-7.4,0-13.4,6-13.4,13.4v18.8c0,7.4,6,13.4,13.4,13.4h37.6c7.4,0,13.4-6,13.4-13.4V46.7 C88.3,39.3,82.3,33.3,74.9,33.3L74.9,33.3z M65.9,57l-17.6,8.4c-0.5,0.2-1-0.1-1-0.6V47.5c0-0.5,0.6-0.9,1-0.6l17.6,8.9 C66.4,56,66.4,56.8,65.9,57L65.9,57z"></path></svg></span>
          </a>
        </div>
        <div class="u-border-1 u-border-white u-expanded-width u-line u-line-horizontal u-opacity u-opacity-50 u-line-1"></div>
      </div></footer>
    <section class="u-backlink u-clearfix u-grey-80">
      <a class="u-link" href="https://nicepage.com/website-templates" target="_blank">
        <span>Website Templates</span>
      </a>
      <p class="u-text">
        <span>created with</span>
      </p>
      <a class="u-link" href="" target="_blank">
        <span>Website Builder Software</span>
      </a>. 
    </section>
  
</body></html>